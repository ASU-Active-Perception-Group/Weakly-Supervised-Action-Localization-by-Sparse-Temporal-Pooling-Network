{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this script we transform the action category to wordembedding and conduct weakly supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load arguments\n",
    "from utils.video_dataset import Dataset\n",
    "\n",
    "import re\n",
    "import torch\n",
    "import string\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import utils.options\n",
    "import torch.nn as nn\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.lr = 0.0001\n",
    "        self.dataset_name = 'Thumos14reduced'\n",
    "        self.num_class = 20\n",
    "        self.feature_size = 2048\n",
    "        self.batch_size = 24\n",
    "        self.max_seqlen = 750\n",
    "        self.model_name = 'weakloc'\n",
    "        self.pretrained_ckpt = None\n",
    "        self.max_iter = 50000\n",
    "        self.num_similar = 3\n",
    "        self.checkpoint_path = './checkpoint/'\n",
    "        self.annotation_path = './annotations/'\n",
    "        self.I3D_path = './I3D_features/'\n",
    "\n",
    "\n",
    "# Category to sentence\n",
    "class_name = {1: [\"baseball pitch\", \"throw a baseball\", \"baseball throw\"],\n",
    "             2: [\"basketball dunk\", \"dunk a basketball\", \"slam dunk basketball\"],\n",
    "             3: [\"billiards\"],\n",
    "             4: [\"clean and jerk\", \"weight lifting movement\"],\n",
    "             5: [\"cliff diving\", \"high diving\", \"diving\"],\n",
    "             6: [\"cricket shot\"],\n",
    "             7: [\"cricket bowling\", \"cricket movment\", \"bowl cricket\"],\n",
    "             8: [\"diving\", \"jumping into water\", \"falling into water\"],\n",
    "             9: [\"frisbee catch\", \"catch frisbee\"],\n",
    "            10: [\"golf swing\", \"golf stroke\"],\n",
    "            11: [\"hammer throw\", \"throw a hammer\"],\n",
    "            12: [\"high jump\"],\n",
    "            13: [\"javelin throw\", \"throw a spear\"],\n",
    "            14: [\"long jump\"],\n",
    "            15: [\"pole vault\", \"a person uses a long flexible pole to jump over a bar\"],\n",
    "            16: [\"shot put\"],\n",
    "            17: [\"soccer penalty\"],\n",
    "            18: [\"tennis swing\"],\n",
    "            19: [\"throw discus\", \"discus\"],\n",
    "            20: [\"volleyball spiking\", \"volleyball\", ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Args()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = Dataset(args)\n",
    "\n",
    "# Word Embedding Loading from GLOVE\n",
    "path_to_glove = './checkpoint/glove.840B.300d.pkl'\n",
    "\n",
    "with open(path_to_glove, \"rb\") as input_file:\n",
    "    glove_model = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up the language model and LSTM\n",
    "\n",
    "class Visual_model(nn.Module):\n",
    "    \"\"\"Args:\n",
    "    feature_dim: dimension of the feature from I3D model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Visual_model, self).__init__()\n",
    "        \n",
    "        self.feature_dim = feature_dim\n",
    "        self.fc0 = nn.Linear(feature_dim, 1024)\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, features_list):\n",
    "        \"\"\"Build the attention module.\n",
    "\n",
    "        Args:\n",
    "        features_list: (batch_size, num_frame, feat_depth)\n",
    "\n",
    "        Returns:\n",
    "        The attention weights, weigted features\n",
    "        \"\"\"\n",
    "        \n",
    "        attention_weights = []\n",
    "        weighted_features = []\n",
    "        \n",
    "        # Iterate through batch\n",
    "        for idx, video_features in enumerate(features_list):\n",
    "                        \n",
    "            # Trunk feature into real length\n",
    "            seq_len = (torch.abs(video_features).max(dim=1)[0] > 0).sum().tolist()\n",
    "            video_features = video_features[: seq_len, :]\n",
    "            \n",
    "            # Iterate through video segments\n",
    "            output = self.sigmoid(self.fc2(self.relu(self.fc1(self.relu(self.fc0(video_features))))))\n",
    "\n",
    "            # Temporal Pool\n",
    "            weighted_pooling = (output*video_features).sum(0)/video_features.shape[0]\n",
    "            \n",
    "            # Save weights/features\n",
    "            output = output.reshape(output.shape[0])\n",
    "            attention_weights.append(output)\n",
    "            weighted_features.append(weighted_pooling)\n",
    "            \n",
    "        # Reshape to tensor\n",
    "        weighted_features = torch.stack(weighted_features)\n",
    "        \n",
    "        return attention_weights, weighted_features\n",
    "\n",
    "\n",
    "\n",
    "class Language_encoder(nn.Module):\n",
    "    \"\"\"Args:\n",
    "    natural language text\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path_to_glove = './checkpoint/glove.840B.300d.pkl'):\n",
    "        super(Language_encoder, self).__init__()\n",
    "        \"\"\"\n",
    "            Load GLOVE pre-trained model first\n",
    "        \"\"\"\n",
    "        with open(path_to_glove, \"rb\") as input_file:\n",
    "            self.glove = pickle.load(input_file)\n",
    "        self.wordnet_lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    def language_preprocess(self, input_str):\n",
    "        # convert to lowercase\n",
    "        input_str = input_str.lower()\n",
    "        # remove numbers\n",
    "        input_str = re.sub(r'\\d+', '', input_str)\n",
    "        # remove punctuation\n",
    "        input_str = re.sub(r'[^\\w\\s]','',input_str)\n",
    "        # remove whitespaces\n",
    "        input_str = input_str.strip()\n",
    "        # remove stop words\n",
    "        stop_words = set(ENGLISH_STOP_WORDS)\n",
    "        tokens = word_tokenize(input_str)\n",
    "        words = [i for i in tokens if not i in stop_words]\n",
    "        # stemming the words\n",
    "        words = [self.wordnet_lemmatizer.lemmatize(word) for word in words]\n",
    "        return words\n",
    "    \n",
    "    def forward(self, text):\n",
    "        text = self.language_preprocess(text)\n",
    "        \n",
    "        return text\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"Args:\n",
    "    feature_dim: dimension of the feature from I3D model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Model, self).__init__()\n",
    "        self.visual_model = Visual_model()\n",
    "        self.language_encoder = Language_encoder()\n",
    "\n",
    "\n",
    "    def forward(self, features_list, text):\n",
    "        \"\"\"Build model architecture.\n",
    "           Consists of two parts: Visual Model + Language Encoder.\n",
    "        \"\"\"\n",
    "        visual_feature = self.visual_model(features_list)\n",
    "        word_vector = self.language_encoder(text)\n",
    "        \n",
    "        return visual_feature, word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Language_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "time_steps = 10\n",
    "batch_size = 3\n",
    "in_size = 5\n",
    "classes_no = 7\n",
    "\n",
    "model = nn.LSTM(in_size, classes_no, 2)\n",
    "input_seq = Variable(torch.randn(time_steps, batch_size, in_size))\n",
    "output_seq, _ = model(input_seq)\n",
    "last_output = output_seq[-1]\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "target = Variable(torch.LongTensor(batch_size).random_(0, classes_no-1))\n",
    "err = loss(last_output, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define our model as a class\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        return y_pred.view(-1)\n",
    "\n",
    "lstm_input_size = 200\n",
    "hidden_dim = 300\n",
    "num_train = 10\n",
    "output_dim = 20\n",
    "num_layers = 2\n",
    "\n",
    "model = LSTM(lstm_input_size, hidden_dim, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
