{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils as util\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "import utils\n",
    "\n",
    "class Dataset():\n",
    "    def __init__(self, args):\n",
    "        self.trainidx = []\n",
    "        self.dataset_name = args.dataset_name\n",
    "        self.path_to_annotations = os.path.join(args.annotation_path, args.dataset_name + '-Annotations/')\n",
    "        self.path_to_features = os.path.join(args.I3D_path, self.dataset_name + '-I3D-JOINTFeatures.npy')\n",
    "        self.labels = np.load(self.path_to_annotations + 'labels_all.npy')     # Specific to Thumos14\n",
    "        self.classlist = np.load(self.path_to_annotations + 'classlist.npy')\n",
    "        self.subset = np.load(self.path_to_annotations + 'subset.npy')\n",
    "        self.testidx = []\n",
    "        self.classwiseidx = []\n",
    "        self.train_test_idx()\n",
    "        self.currenttestidx = 0\n",
    "        self.t_max = args.max_seqlen\n",
    "        self.num_class = args.num_class\n",
    "        self.classwise_feature_mapping()\n",
    "        self.batch_size = args.batch_size\n",
    "        self.feature_size = args.feature_size\n",
    "        self.features = np.load(self.path_to_features, encoding='bytes')\n",
    "        self.segments = np.load(self.path_to_annotations + 'segments.npy')\n",
    "        self.labels_multihot = [util.strlist2multihot(labs,self.classlist) for labs in self.labels]\n",
    "\n",
    "\n",
    "    def train_test_idx(self):\n",
    "        for i, s in enumerate(self.subset):\n",
    "            if s.decode('utf-8') == 'validation':   # Specific to Thumos14\n",
    "                self.trainidx.append(i)\n",
    "            else:\n",
    "                self.testidx.append(i)\n",
    "\n",
    "    def classwise_feature_mapping(self):\n",
    "        for category in self.classlist:\n",
    "            idx = []\n",
    "            for i in self.trainidx:\n",
    "                for label in self.labels[i]:\n",
    "                    if label == category.decode('utf-8'):\n",
    "                        idx.append(i); break;\n",
    "            self.classwiseidx.append(idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.lr = 0.0001\n",
    "        self.dataset_name = 'Thumos14reduced'\n",
    "        self.num_class = 20\n",
    "        self.feature_size = 2048\n",
    "        self.batch_size = 24\n",
    "        self.max_seqlen = 750\n",
    "        self.model_name = 'weakloc'\n",
    "        self.pretrained_ckpt = None\n",
    "        self.max_iter = 50000\n",
    "        self.num_similar = 3\n",
    "        self.checkpoint_path = '/media/drive1/unsupervised_video_action_pt/checkpoint/'\n",
    "        self.annotation_path = '/media/drive1/unsupervised_video_action_pt/annotations/'\n",
    "        self.I3D_path = '/media/drive1/unsupervised_video_action_pt/I3D_features/'\n",
    "\n",
    "args = Args()\n",
    "self = Dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = '/media/drive1/unsupervised_video_action_pt/annotations/Thumos14reduced-Annotations/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtsegments = np.load(annotation_path + '/segments.npy')\n",
    "gtlabels = np.load(annotation_path + '/labels.npy')\n",
    "gtlabels = np.load(annotation_path + '/labels.npy')\n",
    "videoname = np.load(annotation_path + '/videoname.npy'); videoname = np.array([v.decode('utf-8') for v in videoname])\n",
    "subset = np.load(annotation_path + '/subset.npy'); subset = np.array([s.decode('utf-8') for s in subset])\n",
    "classlist = np.load(annotation_path + '/classlist.npy'); classlist = np.array([c.decode('utf-8') for c in classlist])\n",
    "duration = np.load(annotation_path + '/duration.npy')\n",
    "ambilist = annotation_path + '/Ambiguous_test.txt'\n",
    "\n",
    "ambilist = list(open(ambilist,'r'))\n",
    "ambilist = [a.strip('\\n').split(' ') for a in ambilist]\n",
    "\n",
    "# keep training gtlabels for plotting\n",
    "gtltr = []\n",
    "for i, s in enumerate(subset):\n",
    "    if subset[i]=='validation' and len(gtsegments[i]):\n",
    "        gtltr.append(gtlabels[i])\n",
    "gtlabelstr = gtltr\n",
    "\n",
    "# Keep only the test subset annotations\n",
    "gts, gtl, vn, dn = [], [], [], []\n",
    "for i, s in enumerate(subset):\n",
    "    if subset[i] == 'validation':\n",
    "        gts.append(gtsegments[i])\n",
    "        gtl.append(gtlabels[i])\n",
    "        vn.append(videoname[i])\n",
    "        dn.append(duration[i,0])\n",
    "gtsegments = gts\n",
    "gtlabels = gtl\n",
    "videoname = vn\n",
    "duration = dn\n",
    "\n",
    "# keep ground truth and predictions for instances with temporal annotations\n",
    "gts, gtl, vn, pred, dn = [], [], [], [], []\n",
    "for i, s in enumerate(gtsegments):\n",
    "    if len(s):\n",
    "        gts.append(gtsegments[i])\n",
    "        gtl.append(gtlabels[i])\n",
    "        vn.append(videoname[i])\n",
    "        dn.append(duration[i])\n",
    "gtsegments = gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.439"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4.3, 10.9],\n",
       " [16.3, 21.1],\n",
       " [28.5, 36.8],\n",
       " [56.2, 73.0],\n",
       " [85.7, 101.0],\n",
       " [121.4, 141.6]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtsegments[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16569176, 0.04577682, 0.12028474, ..., 0.011098  , 0.02648151,\n",
       "        0.42048913],\n",
       "       [0.18735085, 0.08297902, 0.1321953 , ..., 0.10974882, 0.01641319,\n",
       "        0.        ],\n",
       "       [0.27668834, 0.06708378, 0.13456516, ..., 0.31083372, 0.        ,\n",
       "        0.13812083],\n",
       "       ...,\n",
       "       [0.17345142, 0.10697565, 0.13193522, ..., 0.27103055, 0.9397692 ,\n",
       "        0.02320028],\n",
       "       [0.17254564, 0.13406193, 0.11197495, ..., 0.17237894, 0.23642866,\n",
       "        0.03399808],\n",
       "       [0.15892404, 0.24255729, 0.18422672, ..., 0.00848267, 0.17708796,\n",
       "        0.18079375]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats[12][0:240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
